{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ga_S7QqN45l3MEE0_itN18flHxv4ifBs",
      "authorship_tag": "ABX9TyNNLG7ezG/U4TzeXPqUG61j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShelinVankawala/Reddit-Flair-Detection/blob/main/RedditLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycsyalMYvlti",
        "outputId": "e3cf3f9d-d0bb-4b1b-e2ad-f8c153d12abb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tldextract\n",
            "  Downloading tldextract-3.4.4-py3-none-any.whl (93 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m92.2/93.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.4)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract) (2.27.1)\n",
            "Collecting requests-file>=1.4 (from tldextract)\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.12.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from requests-file>=1.4->tldextract) (1.16.0)\n",
            "Installing collected packages: requests-file, tldextract\n",
            "Successfully installed requests-file-1.5.1 tldextract-3.4.4\n"
          ]
        }
      ],
      "source": [
        "pip install tldextract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install praw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmJQFzmov305",
        "outputId": "515395d3-f702-42d8-b61d-46729bd46442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.7.1-py3-none-any.whl (191 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/191.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/191.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prawcore<3,>=2.1 (from praw)\n",
            "  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n",
            "Collecting update-checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.6.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n",
            "Installing collected packages: update-checker, prawcore, praw\n",
            "Successfully installed praw-7.7.1 prawcore-2.3.0 update-checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "\n",
        "import praw                       # To crawl Reddit and collect data\n",
        "import pandas as pd               # To work with csv files\n",
        "import matplotlib.pyplot as plt   # To plot graphs\n",
        "import requests                   # To send POST requests\n",
        "import time                       # To track time stamp of submissions\n",
        "import pickle                     # To save and load the data we collect"
      ],
      "metadata": {
        "id": "3YX3F7TKv6PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Reddit/reddit-india-data.csv', parse_dates=['timestamp'])"
      ],
      "metadata": {
        "id": "bTLXZljXuYFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flairs = [\"Sports\", \"Politics\", \"AskIndia\", \"Business/Finance\", \"Food\", \"Science/Technology\", \"Non-Political\", \"Photography\", \"Policy/Economy\", \"Scheduled\", \"[R]eddiquette\", \"Food\", \"Coronavirus\", \"Demonetization\", \"CAA-NRC\"]\n",
        "\n",
        "filtered_data = pd.DataFrame(data, columns=['id', 'title', 'score', 'flair'])"
      ],
      "metadata": {
        "id": "VAOw2YG5tt_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "filtered_data.groupby('flair').title.count().plot.bar(ylim=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "SkL8PKCQu1le",
        "outputId": "8052c3da-927f-4097-cc7d-670cabf60cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data.to_csv('balanced_data.csv', index=False)"
      ],
      "metadata": {
        "id": "NwEB_UmmgnOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwKunEIuwr1A",
        "outputId": "0d8cf8f8-2fbf-48a8-c3f5-4d4950b5e134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import Embedding, Layer, Dense, Input, LSTM, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import initializers, regularizers, constraints\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "5wnz613XSVgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/balanced_data.csv')\n",
        "\n",
        "# Tokenize the posts, ie assign keys to each of the words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df.title)\n",
        "X = tokenizer.texts_to_sequences(df.title)\n",
        "df['tokenized'] = X\n",
        "X = list(sequence.pad_sequences(df.tokenized, maxlen=50))\n",
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "I15K9fuySgA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flairs = df.groupby('flair').size().index.tolist()\n",
        "flair_to_key = {}\n",
        "key_to_flair = {}\n",
        "for key, flair in enumerate(flairs):\n",
        "  flair_to_key[flair] = key\n",
        "  key_to_flair[key] = flair\n",
        "\n",
        "df['key'] = df['flair'].apply(lambda x: flair_to_key[x])"
      ],
      "metadata": {
        "id": "58GpRI51StVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "Y = to_categorical(list(df.key))\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.15, stratify=Y)\n",
        "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8jXSshWSuiF",
        "outputId": "252017b1-95fc-4e46-b82a-2ba619da9b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1550, 50) (274, 50) (1550, 8) (274, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(Layer):\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape=(input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "        eij = K.tanh(eij)\n",
        "        a = K.exp(eij)\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0],  self.features_dim"
      ],
      "metadata": {
        "id": "Zau1-g9XSyDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwapjPVqS2dl",
        "outputId": "a10cb053-47cb-40db-932e-e08ad65b8a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preparing the embedding layer using Stanford's 100 dimensional GloVe word vectors: https://nlp.stanford.edu/projects/glove/\n",
        "# First we create a mapping from the words to their vector representation\n",
        "\n",
        "mapping = {}\n",
        "f = open('/content/drive/MyDrive/Reddit/glove.6B.100d.txt')\n",
        "for embedding in f:\n",
        "    embedding = embedding.split()\n",
        "    word = embedding[0]\n",
        "    vector = embedding[1:]\n",
        "    vector = np.asarray(vector, dtype='float32')\n",
        "    mapping[word] = vector\n",
        "f.close()"
      ],
      "metadata": {
        "id": "C2YkcOLwd-ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_weights = np.zeros((len(word_index)+1, 100))\n",
        "for word, idx in word_index.items():\n",
        "    vector = mapping.get(word)\n",
        "    if vector is not None:\n",
        "        embedding_weights[idx] = vector\n",
        "\n",
        "embedding_layer = Embedding(len(word_index)+1, 100, embeddings_initializer=Constant(embedding_weights), input_length=50, trainable=False)\n"
      ],
      "metadata": {
        "id": "YtEiHb5NeU3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(50,), dtype='int32')\n",
        "x = embedding_layer(inputs)\n",
        "x = Bidirectional(LSTM(512, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Attention(50)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = BatchNormalization()(x)\n",
        "outputs = Dense(8, activation='softmax')(x)\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_weights.hdf5', monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "metadata": {
        "id": "8gF3qfyZeY-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_val, y_val), callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSF70qN3edVX",
        "outputId": "cfb0bdc5-f7b4-40bd-f102-669468e4ca21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7389 - acc: 0.7200\n",
            "Epoch 1: val_acc did not improve from 0.56204\n",
            "25/25 [==============================] - 94s 4s/step - loss: 0.7389 - acc: 0.7200 - val_loss: 1.2115 - val_acc: 0.5438\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7112 - acc: 0.7277\n",
            "Epoch 2: val_acc did not improve from 0.56204\n",
            "25/25 [==============================] - 99s 4s/step - loss: 0.7112 - acc: 0.7277 - val_loss: 1.2368 - val_acc: 0.5365\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6723 - acc: 0.7400\n",
            "Epoch 3: val_acc did not improve from 0.56204\n",
            "25/25 [==============================] - 98s 4s/step - loss: 0.6723 - acc: 0.7400 - val_loss: 1.2949 - val_acc: 0.5146\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6306 - acc: 0.7535\n",
            "Epoch 4: val_acc improved from 0.56204 to 0.56934, saving model to best_weights.hdf5\n",
            "25/25 [==============================] - 98s 4s/step - loss: 0.6306 - acc: 0.7535 - val_loss: 1.2114 - val_acc: 0.5693\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6335 - acc: 0.7535\n",
            "Epoch 5: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 99s 4s/step - loss: 0.6335 - acc: 0.7535 - val_loss: 1.2584 - val_acc: 0.5292\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5982 - acc: 0.7723\n",
            "Epoch 6: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.5982 - acc: 0.7723 - val_loss: 1.3205 - val_acc: 0.5292\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5613 - acc: 0.7968\n",
            "Epoch 7: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 96s 4s/step - loss: 0.5613 - acc: 0.7968 - val_loss: 1.2951 - val_acc: 0.5474\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4989 - acc: 0.8194\n",
            "Epoch 8: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 97s 4s/step - loss: 0.4989 - acc: 0.8194 - val_loss: 1.4982 - val_acc: 0.5401\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4768 - acc: 0.8174\n",
            "Epoch 9: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 97s 4s/step - loss: 0.4768 - acc: 0.8174 - val_loss: 1.5259 - val_acc: 0.5474\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4509 - acc: 0.8303\n",
            "Epoch 10: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 99s 4s/step - loss: 0.4509 - acc: 0.8303 - val_loss: 1.5333 - val_acc: 0.5255\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4196 - acc: 0.8452\n",
            "Epoch 11: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 93s 4s/step - loss: 0.4196 - acc: 0.8452 - val_loss: 1.5816 - val_acc: 0.5584\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3895 - acc: 0.8535\n",
            "Epoch 12: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 97s 4s/step - loss: 0.3895 - acc: 0.8535 - val_loss: 1.5484 - val_acc: 0.5292\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3683 - acc: 0.8742\n",
            "Epoch 13: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 96s 4s/step - loss: 0.3683 - acc: 0.8742 - val_loss: 1.6614 - val_acc: 0.5620\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3548 - acc: 0.8697\n",
            "Epoch 14: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 96s 4s/step - loss: 0.3548 - acc: 0.8697 - val_loss: 1.7180 - val_acc: 0.5328\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3487 - acc: 0.8781\n",
            "Epoch 15: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 96s 4s/step - loss: 0.3487 - acc: 0.8781 - val_loss: 1.8122 - val_acc: 0.5401\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2923 - acc: 0.8961\n",
            "Epoch 16: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 96s 4s/step - loss: 0.2923 - acc: 0.8961 - val_loss: 2.0132 - val_acc: 0.5584\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2608 - acc: 0.9097\n",
            "Epoch 17: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 99s 4s/step - loss: 0.2608 - acc: 0.9097 - val_loss: 1.8918 - val_acc: 0.5401\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2439 - acc: 0.9142\n",
            "Epoch 18: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 97s 4s/step - loss: 0.2439 - acc: 0.9142 - val_loss: 1.8665 - val_acc: 0.5511\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2227 - acc: 0.9116\n",
            "Epoch 19: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 94s 4s/step - loss: 0.2227 - acc: 0.9116 - val_loss: 1.9372 - val_acc: 0.5365\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2150 - acc: 0.9284\n",
            "Epoch 20: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.2150 - acc: 0.9284 - val_loss: 2.2210 - val_acc: 0.5328\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2218 - acc: 0.9252\n",
            "Epoch 21: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 96s 4s/step - loss: 0.2218 - acc: 0.9252 - val_loss: 1.9764 - val_acc: 0.5657\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1973 - acc: 0.9406\n",
            "Epoch 22: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 96s 4s/step - loss: 0.1973 - acc: 0.9406 - val_loss: 1.9615 - val_acc: 0.5255\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1627 - acc: 0.9490\n",
            "Epoch 23: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 94s 4s/step - loss: 0.1627 - acc: 0.9490 - val_loss: 2.2184 - val_acc: 0.5292\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1547 - acc: 0.9452\n",
            "Epoch 24: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.1547 - acc: 0.9452 - val_loss: 2.1908 - val_acc: 0.5547\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1676 - acc: 0.9432\n",
            "Epoch 25: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 94s 4s/step - loss: 0.1676 - acc: 0.9432 - val_loss: 2.0522 - val_acc: 0.5474\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1357 - acc: 0.9581\n",
            "Epoch 26: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 93s 4s/step - loss: 0.1357 - acc: 0.9581 - val_loss: 2.1855 - val_acc: 0.5584\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1432 - acc: 0.9523\n",
            "Epoch 27: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 93s 4s/step - loss: 0.1432 - acc: 0.9523 - val_loss: 2.1395 - val_acc: 0.5365\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1231 - acc: 0.9619\n",
            "Epoch 28: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 90s 4s/step - loss: 0.1231 - acc: 0.9619 - val_loss: 2.0724 - val_acc: 0.5547\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1244 - acc: 0.9645\n",
            "Epoch 29: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 99s 4s/step - loss: 0.1244 - acc: 0.9645 - val_loss: 2.2448 - val_acc: 0.5547\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1171 - acc: 0.9626\n",
            "Epoch 30: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.1171 - acc: 0.9626 - val_loss: 2.2858 - val_acc: 0.5109\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1082 - acc: 0.9684\n",
            "Epoch 31: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 94s 4s/step - loss: 0.1082 - acc: 0.9684 - val_loss: 2.1672 - val_acc: 0.5438\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0975 - acc: 0.9658\n",
            "Epoch 32: val_acc did not improve from 0.56934\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.0975 - acc: 0.9658 - val_loss: 2.2031 - val_acc: 0.5511\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0834 - acc: 0.9774\n",
            "Epoch 33: val_acc improved from 0.56934 to 0.57299, saving model to best_weights.hdf5\n",
            "25/25 [==============================] - 93s 4s/step - loss: 0.0834 - acc: 0.9774 - val_loss: 2.1446 - val_acc: 0.5730\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0840 - acc: 0.9755\n",
            "Epoch 34: val_acc did not improve from 0.57299\n",
            "25/25 [==============================] - 91s 4s/step - loss: 0.0840 - acc: 0.9755 - val_loss: 2.2673 - val_acc: 0.5255\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0895 - acc: 0.9742\n",
            "Epoch 35: val_acc did not improve from 0.57299\n",
            "25/25 [==============================] - 96s 4s/step - loss: 0.0895 - acc: 0.9742 - val_loss: 2.3643 - val_acc: 0.5109\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0744 - acc: 0.9781\n",
            "Epoch 36: val_acc did not improve from 0.57299\n",
            "25/25 [==============================] - 93s 4s/step - loss: 0.0744 - acc: 0.9781 - val_loss: 2.5922 - val_acc: 0.5547\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0706 - acc: 0.9768\n",
            "Epoch 37: val_acc did not improve from 0.57299\n",
            "25/25 [==============================] - 93s 4s/step - loss: 0.0706 - acc: 0.9768 - val_loss: 2.3277 - val_acc: 0.5328\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0722 - acc: 0.9787\n",
            "Epoch 38: val_acc did not improve from 0.57299\n",
            "25/25 [==============================] - 93s 4s/step - loss: 0.0722 - acc: 0.9787 - val_loss: 2.2308 - val_acc: 0.5511\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0761 - acc: 0.9800\n",
            "Epoch 39: val_acc did not improve from 0.57299\n",
            "25/25 [==============================] - 91s 4s/step - loss: 0.0761 - acc: 0.9800 - val_loss: 2.2882 - val_acc: 0.5401\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0724 - acc: 0.9794\n",
            "Epoch 40: val_acc did not improve from 0.57299\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.0724 - acc: 0.9794 - val_loss: 2.4396 - val_acc: 0.5219\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0556 - acc: 0.9806\n",
            "Epoch 41: val_acc did not improve from 0.57299\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.0556 - acc: 0.9806 - val_loss: 2.4634 - val_acc: 0.5474\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0444 - acc: 0.9890\n",
            "Epoch 42: val_acc did not improve from 0.57299\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.0444 - acc: 0.9890 - val_loss: 2.4955 - val_acc: 0.5620\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0386 - acc: 0.9910\n",
            "Epoch 43: val_acc did not improve from 0.57299\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.0386 - acc: 0.9910 - val_loss: 2.5501 - val_acc: 0.5511\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0533 - acc: 0.9845\n",
            "Epoch 44: val_acc did not improve from 0.57299\n",
            "25/25 [==============================] - 93s 4s/step - loss: 0.0533 - acc: 0.9845 - val_loss: 2.5628 - val_acc: 0.5657\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0378 - acc: 0.9923\n",
            "Epoch 45: val_acc did not improve from 0.57299\n",
            "25/25 [==============================] - 94s 4s/step - loss: 0.0378 - acc: 0.9923 - val_loss: 2.4932 - val_acc: 0.5474\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0375 - acc: 0.9890\n",
            "Epoch 46: val_acc improved from 0.57299 to 0.57664, saving model to best_weights.hdf5\n",
            "25/25 [==============================] - 94s 4s/step - loss: 0.0375 - acc: 0.9890 - val_loss: 2.4698 - val_acc: 0.5766\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0757 - acc: 0.9781\n",
            "Epoch 47: val_acc did not improve from 0.57664\n",
            "25/25 [==============================] - 94s 4s/step - loss: 0.0757 - acc: 0.9781 - val_loss: 2.6637 - val_acc: 0.5182\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0983 - acc: 0.9723\n",
            "Epoch 48: val_acc did not improve from 0.57664\n",
            "25/25 [==============================] - 92s 4s/step - loss: 0.0983 - acc: 0.9723 - val_loss: 2.5225 - val_acc: 0.5219\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0760 - acc: 0.9761\n",
            "Epoch 49: val_acc did not improve from 0.57664\n",
            "25/25 [==============================] - 95s 4s/step - loss: 0.0760 - acc: 0.9761 - val_loss: 2.2485 - val_acc: 0.5474\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0696 - acc: 0.9800\n",
            "Epoch 50: val_acc did not improve from 0.57664\n",
            "25/25 [==============================] - 94s 4s/step - loss: 0.0696 - acc: 0.9800 - val_loss: 2.2348 - val_acc: 0.5438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle_out = open(\"tokenizer.pickle\", \"wb\")\n",
        "pickle.dump(tokenizer, pickle_out)\n",
        "pickle_out.close()"
      ],
      "metadata": {
        "id": "2q3LiaNd6ziz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"best_weights.hdf5\")"
      ],
      "metadata": {
        "id": "p-KiPO7065dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "\n",
        "preds = model.predict(x_val)\n",
        "y = np.asarray([np.argmax(line) for line in y_val])\n",
        "preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "print(\"Accuracy = {}\".format(accuracy_score(y, preds)))\n",
        "print(\"F1 score = {}\".format(f1_score(y, preds, average='macro')))\n",
        "print(\"Precision = {}\".format(precision_score(y, preds, average='macro')))\n",
        "print(\"Recall = {}\".format(recall_score(y, preds, average='macro')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05kwYIJf68HG",
        "outputId": "56b68813-e48d-4a31-daf2-c8aa5cc06483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 6s 634ms/step\n",
            "Accuracy = 0.5766423357664233\n",
            "F1 score = 0.5557675612227422\n",
            "Precision = 0.5544982452315278\n",
            "Recall = 0.5673798798798798\n"
          ]
        }
      ]
    }
  ]
}